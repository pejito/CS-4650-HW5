# -*- coding: utf-8 -*-
"""CS 4650 HW5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_BNacCFgtfVX4oTwMAvL1ofzk2m4VrCW
"""

!pip install spacy
!pip install newsapi-python

!python -m spacy download en_core_web_lg

import spacy
from newsapi import NewsApiClient
import pandas as pd
import en_core_web_lg
import pickle
from collections import Counter
from google.colab import drive
import string
import matplotlib.pyplot as plt
from wordcloud import WordCloud

nlp_eng = en_core_web_lg.load()
newsapi = NewsApiClient (api_key = 'b241f3e69a4443b08e37884639e6afd2')

articles = []
for i in range(1, 6):
  temp = newsapi.get_everything(q='coronavirus', language='en', from_param='2021-02-23', to='2021-03-21', sort_by='relevancy', page=i)
  articles.append(temp)

dados = []
for i, article in enumerate(articles):
    for x in article['articles']:
        title = x['title']
        description = x['description']
        date = x['publishedAt']
        content = x['content']
        dados.append({'title':title[0], 'date':date[0], 'desc':description[0], 'content':content})
df = pd.DataFrame(dados)
df = df.dropna()
df.head()

def get_keywords_eng(sect):
  result = []
  pos_tag = ['PROPN', 'VERB', 'NOUN']
  nlp = spacy.load('en_core_web_sm')
  doc = nlp(sect)
  for token in doc:
    if (token.text in nlp_eng.Defaults.stop_words or token.text in string.punctuation):
      continue
    if (token.pos_ in pos_tag):
      result.append(token.text)
  return result

results = []
for content in df.content.values:
    results.append([('#' + x[0]) for x in Counter(get_keywords_eng(content)).most_common(5)])
df['keywords'] = results

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()